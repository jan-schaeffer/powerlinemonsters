{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 =  pd.read_excel(f'{path}/data/elections/btw/ags_trans/2002.xlsx', converters = {'Land': str, 'RB': str, 'Kreis': str, 'VB': str, 'Gem': str})\n",
    "df05 =  pd.read_excel(f'{path}/data/elections/btw/ags_trans/2005.xlsx', converters = {'Land': str, 'RB': str, 'Kreis': str, 'VB': str, 'Gem': str})\n",
    "df09 =  pd.read_excel(f'{path}/data/elections/btw/ags_trans/2009.xlsx', converters = {'Land': str, 'RB': str, 'Kreis': str, 'VB': str, 'Gem': str})\n",
    "df13 =  pd.read_excel(f'{path}/data/elections/btw/ags_trans/2013.xlsx', converters = {'Land': str, 'RB': str, 'Kreis': str, 'VB': str, 'Gem': str})\n",
    "df17 =  pd.read_excel(f'{path}/data/elections/btw/ags_trans/2017.xlsx', converters = {'Land': str, 'RB': str, 'Kreis': str, 'VB': str, 'Gem': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df02, df05, df09, df13, df17]\n",
    "for df in dfs:\n",
    "    try:\n",
    "        df.insert(loc=0, column='AGS', value=0)\n",
    "    except Exception:\n",
    "        pass\n",
    "    df['AGS'] = df['Land'] + df['RB'] + df['Kreis'] + df['Gem']\n",
    "    df = df.sort_values(['AGS'])\n",
    "    df = df.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "    df = df.reindex(columns=['AGS', 'Gemeindename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 = df02.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "df05 = df05.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "df09 = df09.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "df13 = df13.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "df17 = df17.dropna(axis='rows', how='any', subset=['AGS'])\n",
    "df02 = df02.reindex(columns=['AGS', 'Gemeindename'])\n",
    "df05 = df05.reindex(columns=['AGS', 'Gemeindename'])\n",
    "df09 = df09.reindex(columns=['AGS', 'Gemeindename'])\n",
    "df13 = df13.reindex(columns=['AGS', 'Gemeindename'])\n",
    "df17 = df17.reindex(columns=['AGS', 'Gemeindename'])\n",
    "df02.rename(columns = {'AGS':'AGS_02', 'Gemeindename': 'Gemeindename_02'}, inplace = True)\n",
    "df05.rename(columns = {'AGS':'AGS_05', 'Gemeindename': 'Gemeindename_05'}, inplace = True)\n",
    "df09.rename(columns = {'AGS':'AGS_09', 'Gemeindename': 'Gemeindename_09'}, inplace = True)\n",
    "df13.rename(columns = {'AGS':'AGS_13', 'Gemeindename': 'Gemeindename_13'}, inplace = True)\n",
    "df17.rename(columns = {'AGS':'AGS_17', 'Gemeindename': 'Gemeindename_17'}, inplace = True)\n",
    "df17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0213 = pd.merge(df02, df13, how='left', left_on='AGS_02', right_on='AGS_13', indicator=True)\n",
    "print(df0213['_merge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0513 = pd.merge(df05, df13, how='left', left_on='AGS_05', right_on='AGS_13', indicator=True)\n",
    "print(df0513['_merge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0913 = pd.merge(df09, df13, how='left', left_on='AGS_09', right_on='AGS_13', indicator=True)\n",
    "print(df0913['_merge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1713 = pd.merge(df17, df13, how='left', left_on='AGS_17', right_on='AGS_13', indicator=True)\n",
    "print(df1713['_merge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df13, df02, how='left', left_on='AGS_13', right_on='AGS_02', indicator='merge0213')\n",
    "df = pd.merge(df, df05, how='left', left_on='AGS_13', right_on='AGS_05', indicator='merge0513')\n",
    "df = pd.merge(df, df09, how='left', left_on='AGS_13', right_on='AGS_09', indicator='merge0913')\n",
    "df = pd.merge(df, df17, how='left', left_on='AGS_13', right_on='AGS_17', indicator='merge1713')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ags_dup'] = df.duplicated(subset=['AGS_13'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['AGS_13'], as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\n",
    "vars = ['merge0213', 'merge0513', 'merge0913', 'merge1713']\n",
    "for var in vars:\n",
    "    df = df[df[var] == 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['Gemeindename_13', 'AGS_13'])\n",
    "df.rename(columns = {'AGS_13':'AGS', 'Gemeindename_13':'Gemeindename'}, inplace = True)\n",
    "df.to_csv(f'{path}/data/ags_trans.csv', encoding = 'utf-8-sig')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities = gpd.read_file(f'{path}/data/geodata/VG250_GEM.shp')\n",
    "states = gpd.read_file(f'{path}/data/geodata/VG250_LAN.shp')\n",
    "powerlines = gpd.read_file(f'{path}/data/geodata/powerlines.shp')\n",
    "powerlines = powerlines[powerlines['New'] == 1]\n",
    "matched_mun_pd = pd.merge(df, municipalities, on='AGS', how='left', indicator=True).drop(columns='geometry')\n",
    "matched_mun  = pd.merge(municipalities, df, on='AGS', how='left', indicator=True)\n",
    "matched_mun = matched_mun[matched_mun['_merge'] == 'both']\n",
    "print(matched_mun_pd['_merge'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_axis_off()\n",
    "matched_mun.plot(ax=ax, color='lightblue', zorder=1)\n",
    "states.boundary.plot(ax=ax, color='black', lw = 0.1, zorder=2)\n",
    "powerlines.plot(ax=ax, color='red', lw=2, zorder=3)\n",
    "plt.suptitle('Not merged municipalities', fontsize=20)\n",
    "plt.title('Balanced panel', fontsize=10)\n",
    "plt.savefig(f'{path}/figures/not_merged_balanced.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88be3cbefcf0764a65175a6561fd304411aaded24422f3185dd5fe11d8fe4862"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vscode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
